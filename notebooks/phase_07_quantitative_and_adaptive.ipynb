{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 7: Quantitative & Adaptive Analysis\n",
    "\n",
    "Data-driven models for edge detection and real-time adaptation.\n",
    "\n",
    "This notebook covers:\n",
    "- **Statistical arbitrage** — pairs trading and mean reversion\n",
    "- **Machine learning signals** — feature engineering and model training\n",
    "- **Regime detection** — identifying market states\n",
    "- **Adaptive parameter tuning** — dynamic strategy adjustment\n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy matplotlib scipy scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_prices(n=500, mu=0.08, sigma=0.20, start=100.0):\n",
    "    dt = 1/252\n",
    "    returns = np.random.normal(mu * dt, sigma * np.sqrt(dt), n)\n",
    "    prices = start * np.exp(np.cumsum(returns))\n",
    "    dates = pd.date_range('2023-01-01', periods=n, freq='B')\n",
    "    return pd.Series(prices, index=dates, name='close')\n",
    "\n",
    "prices = generate_prices(750)\n",
    "returns = prices.pct_change().dropna()\n",
    "print(f\"Generated {len(prices)} price points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.1 Pairs Trading (Statistical Arbitrage)\n",
    "\n",
    "Find two cointegrated assets and trade the spread when it deviates from equilibrium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cointegrated pair\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "# Common factor\n",
    "common = np.cumsum(np.random.normal(0.0003, 0.015, n))\n",
    "# Asset A = common + noise\n",
    "asset_a = 100 * np.exp(common + np.cumsum(np.random.normal(0, 0.005, n)))\n",
    "# Asset B = 0.8 * common + noise (cointegrated with A)\n",
    "asset_b = 80 * np.exp(0.8 * common + np.cumsum(np.random.normal(0, 0.005, n)))\n",
    "\n",
    "dates = pd.date_range('2023-01-01', periods=n, freq='B')\n",
    "pair_df = pd.DataFrame({'A': asset_a, 'B': asset_b}, index=dates)\n",
    "\n",
    "def compute_spread(a, b, lookback=60):\n",
    "    \"\"\"Compute z-score of log spread.\"\"\"\n",
    "    log_ratio = np.log(a / b)\n",
    "    mean = log_ratio.rolling(lookback).mean()\n",
    "    std = log_ratio.rolling(lookback).std()\n",
    "    z_score = (log_ratio - mean) / std\n",
    "    return z_score, log_ratio\n",
    "\n",
    "z_score, log_ratio = compute_spread(pair_df['A'], pair_df['B'])\n",
    "\n",
    "def pairs_trading_backtest(\n",
    "    pair_df, z_score,\n",
    "    entry_z: float = 2.0,\n",
    "    exit_z: float = 0.5,\n",
    "    stop_z: float = 3.5,\n",
    "    leverage: float = 2.0\n",
    "):\n",
    "    returns_a = pair_df['A'].pct_change()\n",
    "    returns_b = pair_df['B'].pct_change()\n",
    "    \n",
    "    position = 0  # 1 = long spread (long A, short B), -1 = short spread\n",
    "    strat_returns = []\n",
    "    positions = []\n",
    "    \n",
    "    for i in range(1, len(z_score)):\n",
    "        z = z_score.iloc[i]\n",
    "        if np.isnan(z):\n",
    "            strat_returns.append(0)\n",
    "            positions.append(0)\n",
    "            continue\n",
    "        \n",
    "        # Entry\n",
    "        if position == 0:\n",
    "            if z > entry_z:\n",
    "                position = -1  # short spread: short A, long B\n",
    "            elif z < -entry_z:\n",
    "                position = 1   # long spread: long A, short B\n",
    "        \n",
    "        # Exit\n",
    "        elif position == 1:\n",
    "            if z > -exit_z or z > stop_z:\n",
    "                position = 0\n",
    "        elif position == -1:\n",
    "            if z < exit_z or z < -stop_z:\n",
    "                position = 0\n",
    "        \n",
    "        # Calculate return: long A, short B (or vice versa)\n",
    "        spread_return = position * (returns_a.iloc[i] - returns_b.iloc[i]) * leverage\n",
    "        strat_returns.append(spread_return)\n",
    "        positions.append(position)\n",
    "    \n",
    "    return pd.Series(strat_returns, index=z_score.index[1:]), pd.Series(positions, index=z_score.index[1:])\n",
    "\n",
    "strat_ret, positions = pairs_trading_backtest(pair_df, z_score)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12), sharex=True, gridspec_kw={'height_ratios': [2, 1, 1, 2]})\n",
    "\n",
    "# Prices\n",
    "axes[0].plot(pair_df.index, pair_df['A'], label='Asset A')\n",
    "axes[0].plot(pair_df.index, pair_df['B'], label='Asset B')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].set_title('Pairs Trading: Cointegrated Assets', fontsize=14)\n",
    "axes[0].legend()\n",
    "\n",
    "# Z-score\n",
    "axes[1].plot(z_score.index, z_score, color='purple')\n",
    "axes[1].axhline(y=2, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].axhline(y=-2, color='green', linestyle='--', alpha=0.5)\n",
    "axes[1].axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "axes[1].set_ylabel('Z-Score')\n",
    "axes[1].set_ylim(-4, 4)\n",
    "\n",
    "# Position\n",
    "axes[2].fill_between(positions.index, positions, 0, alpha=0.3, step='post')\n",
    "axes[2].set_ylabel('Position')\n",
    "axes[2].set_ylim(-1.5, 1.5)\n",
    "\n",
    "# Cumulative return\n",
    "cum_ret = (1 + strat_ret).cumprod()\n",
    "axes[3].plot(cum_ret.index, cum_ret, color='green', linewidth=1.5)\n",
    "axes[3].axhline(y=1, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[3].set_ylabel('Cumulative Return')\n",
    "axes[3].set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total return: {(cum_ret.iloc[-1] - 1):.2%}\")\n",
    "print(f\"Sharpe ratio: {strat_ret.mean() / strat_ret.std() * np.sqrt(252):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.1\n",
    "\n",
    "1. Change `entry_z` to 1.5 (more trades) and 2.5 (fewer trades). Which has a better Sharpe ratio?\n",
    "2. The spread can \"break\" — cointegration can fail. Add a check that exits all positions if the 60-day correlation drops below 0.5.\n",
    "3. Research the Augmented Dickey-Fuller (ADF) test for cointegration. How would you use it to select pairs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.2 Machine Learning Signals\n",
    "\n",
    "Use features derived from price data to predict next-day direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(prices: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Engineer features for ML model.\"\"\"\n",
    "    df = pd.DataFrame(index=prices.index)\n",
    "    df['price'] = prices\n",
    "    df['return_1d'] = prices.pct_change()\n",
    "    df['return_5d'] = prices.pct_change(5)\n",
    "    df['return_20d'] = prices.pct_change(20)\n",
    "    \n",
    "    # Momentum\n",
    "    df['mom_10'] = prices / prices.shift(10) - 1\n",
    "    df['mom_30'] = prices / prices.shift(30) - 1\n",
    "    \n",
    "    # Volatility\n",
    "    df['vol_10'] = df['return_1d'].rolling(10).std()\n",
    "    df['vol_30'] = df['return_1d'].rolling(30).std()\n",
    "    df['vol_ratio'] = df['vol_10'] / df['vol_30']\n",
    "    \n",
    "    # Mean reversion\n",
    "    df['dist_ma20'] = prices / prices.rolling(20).mean() - 1\n",
    "    df['dist_ma50'] = prices / prices.rolling(50).mean() - 1\n",
    "    \n",
    "    # RSI\n",
    "    delta = prices.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    df['rsi'] = 100 - 100 / (1 + gain / loss)\n",
    "    \n",
    "    # Target: next day positive return\n",
    "    df['target'] = (df['return_1d'].shift(-1) > 0).astype(int)\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "features_df = create_features(prices)\n",
    "feature_cols = ['return_1d', 'return_5d', 'return_20d', 'mom_10', 'mom_30',\n",
    "                'vol_10', 'vol_30', 'vol_ratio', 'dist_ma20', 'dist_ma50', 'rsi']\n",
    "\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"Samples: {len(features_df)}\")\n",
    "print(f\"Target distribution: {features_df['target'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_ml_backtest(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: list,\n",
    "    train_size: int = 252,\n",
    "    test_size: int = 21,\n",
    "    leverage: float = 2.0\n",
    "):\n",
    "    \"\"\"Walk-forward ML backtest with periodic retraining.\"\"\"\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    dates = []\n",
    "    \n",
    "    for start in range(train_size, len(df) - test_size, test_size):\n",
    "        # Training data\n",
    "        train = df.iloc[start - train_size:start]\n",
    "        X_train = train[feature_cols]\n",
    "        y_train = train['target']\n",
    "        \n",
    "        # Test data\n",
    "        test = df.iloc[start:start + test_size]\n",
    "        X_test = test[feature_cols]\n",
    "        y_test = test['target']\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Train model\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        probs = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        predictions.extend(probs)\n",
    "        actuals.extend(y_test.values)\n",
    "        dates.extend(test.index)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'prob': predictions,\n",
    "        'actual': actuals,\n",
    "        'return': df.loc[dates, 'return_1d'].shift(-1).values\n",
    "    }, index=dates)\n",
    "    \n",
    "    # Strategy: go long if prob > 0.55, short if prob < 0.45, else flat\n",
    "    results['position'] = 0\n",
    "    results.loc[results['prob'] > 0.55, 'position'] = 1\n",
    "    results.loc[results['prob'] < 0.45, 'position'] = -1\n",
    "    \n",
    "    results['strat_return'] = results['position'] * results['return'] * leverage\n",
    "    \n",
    "    return results.dropna()\n",
    "\n",
    "ml_results = walk_forward_ml_backtest(features_df, feature_cols)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Predicted probabilities\n",
    "axes[0].plot(ml_results.index, ml_results['prob'], color='steelblue', linewidth=0.8)\n",
    "axes[0].axhline(y=0.55, color='green', linestyle='--', alpha=0.5)\n",
    "axes[0].axhline(y=0.45, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0].set_ylabel('Predicted Prob (Up)')\n",
    "axes[0].set_title('ML Signal: Random Forest Walk-Forward', fontsize=14)\n",
    "\n",
    "# Position\n",
    "axes[1].fill_between(ml_results.index, ml_results['position'], 0, alpha=0.3, step='post')\n",
    "axes[1].set_ylabel('Position')\n",
    "\n",
    "# Cumulative returns\n",
    "cum_strat = (1 + ml_results['strat_return']).cumprod()\n",
    "cum_bh = (1 + ml_results['return']).cumprod()\n",
    "axes[2].plot(cum_strat.index, cum_strat, color='green', label='ML Strategy (2x lev)')\n",
    "axes[2].plot(cum_bh.index, cum_bh, color='gray', linestyle='--', label='Buy & Hold')\n",
    "axes[2].axhline(y=1, color='gray', alpha=0.3)\n",
    "axes[2].set_ylabel('Cumulative Return')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "accuracy = (ml_results['prob'].round() == ml_results['actual']).mean()\n",
    "print(f\"Prediction accuracy: {accuracy:.1%}\")\n",
    "print(f\"Strategy return: {(cum_strat.iloc[-1] - 1):.2%}\")\n",
    "print(f\"Buy & hold return: {(cum_bh.iloc[-1] - 1):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.2\n",
    "\n",
    "1. Add more features: Bollinger Band position, MACD histogram, volume ratio. Does accuracy improve?\n",
    "2. Change the probability thresholds from 0.55/0.45 to 0.6/0.4. Fewer trades but higher conviction — better Sharpe?\n",
    "3. Why is walk-forward validation essential for ML trading strategies? What happens if you train on all data and test on all data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.3 Regime Detection\n",
    "\n",
    "Markets move through different regimes (trending, mean-reverting, high-vol, low-vol). Detecting the current regime helps select the right strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_regimes(prices: pd.Series, vol_lookback=20, trend_lookback=50):\n",
    "    \"\"\"Simple regime detection based on volatility and trend.\"\"\"\n",
    "    returns = prices.pct_change()\n",
    "    \n",
    "    # Volatility regime\n",
    "    vol = returns.rolling(vol_lookback).std() * np.sqrt(252)\n",
    "    vol_median = vol.rolling(252).median()\n",
    "    high_vol = vol > vol_median * 1.2\n",
    "    \n",
    "    # Trend regime (ADX-like)\n",
    "    ma = prices.rolling(trend_lookback).mean()\n",
    "    dist_from_ma = (prices - ma) / ma\n",
    "    trending = dist_from_ma.abs() > 0.05  # >5% from MA = trending\n",
    "    \n",
    "    # Combine into 4 regimes\n",
    "    regime = pd.Series('unknown', index=prices.index)\n",
    "    regime[(~high_vol) & (~trending)] = 'low_vol_range'\n",
    "    regime[(~high_vol) & (trending)] = 'low_vol_trend'\n",
    "    regime[(high_vol) & (~trending)] = 'high_vol_range'\n",
    "    regime[(high_vol) & (trending)] = 'high_vol_trend'\n",
    "    \n",
    "    return regime, vol, trending\n",
    "\n",
    "regime, vol, trending = detect_regimes(prices)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Price with regime coloring\n",
    "colors = {'low_vol_range': 'blue', 'low_vol_trend': 'green', \n",
    "          'high_vol_range': 'orange', 'high_vol_trend': 'red', 'unknown': 'gray'}\n",
    "for r in colors:\n",
    "    mask = regime == r\n",
    "    if mask.any():\n",
    "        axes[0].scatter(prices.index[mask], prices[mask], c=colors[r], s=5, label=r, alpha=0.7)\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].set_title('Regime Detection', fontsize=14)\n",
    "axes[0].legend(fontsize=8)\n",
    "\n",
    "# Volatility\n",
    "axes[1].plot(vol.index, vol * 100, color='purple')\n",
    "axes[1].axhline(y=vol.median() * 100, color='gray', linestyle='--')\n",
    "axes[1].set_ylabel('Annualized Vol (%)')\n",
    "\n",
    "# Regime distribution\n",
    "regime_counts = regime.value_counts()\n",
    "axes[2].bar(regime_counts.index, regime_counts.values, color=[colors[r] for r in regime_counts.index])\n",
    "axes[2].set_ylabel('Days')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Regime distribution:\")\n",
    "for r, count in regime_counts.items():\n",
    "    print(f\"  {r}: {count} days ({count/len(regime):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy selection based on regime\n",
    "def regime_adaptive_strategy(prices, regime, leverage=2.0):\n",
    "    returns = prices.pct_change()\n",
    "    ma_fast = prices.ewm(span=10).mean()\n",
    "    ma_slow = prices.ewm(span=30).mean()\n",
    "    \n",
    "    # Mean reversion signal\n",
    "    z = (prices - prices.rolling(20).mean()) / prices.rolling(20).std()\n",
    "    mr_signal = -np.sign(z)  # fade extremes\n",
    "    \n",
    "    # Trend signal\n",
    "    trend_signal = np.sign(ma_fast - ma_slow)\n",
    "    \n",
    "    # Select strategy based on regime\n",
    "    position = pd.Series(0.0, index=prices.index)\n",
    "    \n",
    "    # Trending regimes: use trend following\n",
    "    trending_mask = regime.isin(['low_vol_trend', 'high_vol_trend'])\n",
    "    position[trending_mask] = trend_signal[trending_mask]\n",
    "    \n",
    "    # Range regimes: use mean reversion\n",
    "    range_mask = regime.isin(['low_vol_range', 'high_vol_range'])\n",
    "    position[range_mask] = mr_signal[range_mask].where(z.abs() > 1.5, 0)\n",
    "    \n",
    "    # Reduce leverage in high vol\n",
    "    high_vol_mask = regime.isin(['high_vol_range', 'high_vol_trend'])\n",
    "    position[high_vol_mask] *= 0.5\n",
    "    \n",
    "    strat_return = position.shift(1) * returns * leverage\n",
    "    return strat_return, position\n",
    "\n",
    "adaptive_ret, adaptive_pos = regime_adaptive_strategy(prices, regime)\n",
    "\n",
    "# Compare to static trend following\n",
    "ma_fast = prices.ewm(span=10).mean()\n",
    "ma_slow = prices.ewm(span=30).mean()\n",
    "static_pos = np.sign(ma_fast - ma_slow)\n",
    "static_ret = static_pos.shift(1) * prices.pct_change() * 2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "cum_adaptive = (1 + adaptive_ret.dropna()).cumprod()\n",
    "cum_static = (1 + static_ret.dropna()).cumprod()\n",
    "cum_bh = (1 + prices.pct_change().dropna()).cumprod()\n",
    "\n",
    "ax.plot(cum_adaptive.index, cum_adaptive, color='green', linewidth=1.5, label='Regime Adaptive')\n",
    "ax.plot(cum_static.index, cum_static, color='blue', linewidth=1.5, label='Static Trend')\n",
    "ax.plot(cum_bh.index, cum_bh, color='gray', linestyle='--', label='Buy & Hold')\n",
    "ax.axhline(y=1, color='gray', alpha=0.3)\n",
    "ax.set_title('Regime-Adaptive vs Static Strategy', fontsize=14)\n",
    "ax.set_ylabel('Cumulative Return')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Adaptive: {(cum_adaptive.iloc[-1]-1):.2%}, Sharpe: {adaptive_ret.mean()/adaptive_ret.std()*np.sqrt(252):.2f}\")\n",
    "print(f\"Static:   {(cum_static.iloc[-1]-1):.2%}, Sharpe: {static_ret.mean()/static_ret.std()*np.sqrt(252):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.3\n",
    "\n",
    "1. Add a \"crisis\" regime when volatility is >2x the median. What strategy works best in crisis?\n",
    "2. Use a Hidden Markov Model (HMM) to detect regimes instead of simple thresholds. Does it improve timing?\n",
    "3. Calculate the Sharpe ratio of trend following ONLY during trending regimes vs ONLY during ranging regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.4 Comprehension Check\n",
    "\n",
    "1. Why do pairs trading strategies require cointegration rather than just correlation?\n",
    "2. What is the main risk of ML-based trading strategies? (Hint: overfitting)\n",
    "3. How would you test if your regime detection is actually predictive vs just descriptive?\n",
    "4. A model has 55% accuracy predicting next-day direction. Is this good enough to trade profitably? What else matters?\n",
    "5. Why do quantitative strategies often have capacity limits (can't deploy unlimited capital)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWERS HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
